{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7156377 [array([[ 0.7926959 ,  0.6886104 ],\n",
      "       [-1.2072834 , -0.29517072]], dtype=float32), array([[1.7177    ],\n",
      "       [0.35572484]], dtype=float32)]\n",
      "100 0.6907327 [array([[ 0.32268244, -0.23303036],\n",
      "       [-0.7743417 ,  0.8052943 ]], dtype=float32), array([[1.4608113 ],\n",
      "       [0.78415203]], dtype=float32)]\n",
      "200 0.49503163 [array([[ 1.6721692, -2.3216543],\n",
      "       [-2.2168636,  2.6561468]], dtype=float32), array([[2.8243914],\n",
      "       [2.6025808]], dtype=float32)]\n",
      "300 0.22374642 [array([[ 3.1877632, -3.7442877],\n",
      "       [-3.6972432,  4.1295667]], dtype=float32), array([[4.7004085],\n",
      "       [4.3188057]], dtype=float32)]\n",
      "400 0.12229483 [array([[ 3.9886725, -4.520833 ],\n",
      "       [-4.4841404,  4.903435 ]], dtype=float32), array([[5.8487263],\n",
      "       [5.4189944]], dtype=float32)]\n",
      "500 0.078843184 [array([[ 4.4861465, -5.0151863],\n",
      "       [-4.973251 ,  5.39077  ]], dtype=float32), array([[6.6447487],\n",
      "       [6.2020254]], dtype=float32)]\n",
      "600 0.055981167 [array([[ 4.839386 , -5.370661 ],\n",
      "       [-5.3210588,  5.7398577]], dtype=float32), array([[7.2586293],\n",
      "       [6.8132977]], dtype=float32)]\n",
      "700 0.04224272 [array([[ 5.111045 , -5.645957 ],\n",
      "       [-5.5889034,  6.009811 ]], dtype=float32), array([[7.7626452],\n",
      "       [7.3183374]], dtype=float32)]\n",
      "800 0.033227302 [array([[ 5.3308954, -5.8696966],\n",
      "       [-5.8059134,  6.2290907]], dtype=float32), array([[8.193123],\n",
      "       [7.751217]], dtype=float32)]\n",
      "900 0.026933454 [array([[ 5.515177 , -6.057749 ],\n",
      "       [-5.9879947,  6.413374 ]], dtype=float32), array([[8.57083 ],\n",
      "       [8.131825]], dtype=float32)]\n",
      "1000 0.022333965 [array([[ 5.67365  , -6.219753 ],\n",
      "       [-6.1447105,  6.572153 ]], dtype=float32), array([[8.90876 ],\n",
      "       [8.472787]], dtype=float32)]\n",
      "1100 0.01885244 [array([[ 5.812608 , -6.3619866],\n",
      "       [-6.282229 ,  6.711584 ]], dtype=float32), array([[9.215611],\n",
      "       [8.78262 ]], dtype=float32)]\n",
      "1200 0.016142853 [array([[ 5.9363365, -6.4887395],\n",
      "       [-6.4047527,  6.8358717]], dtype=float32), array([[9.497477 ],\n",
      "       [9.0673685]], dtype=float32)]\n",
      "1300 0.013985719 [array([[ 6.0478745, -6.6030784],\n",
      "       [-6.5152693,  6.9480157]], dtype=float32), array([[9.758837],\n",
      "       [9.331477]], dtype=float32)]\n",
      "1400 0.0122359805 [array([[ 6.1494503, -6.7072563],\n",
      "       [-6.615971 ,  7.0502205]], dtype=float32), array([[10.003056],\n",
      "       [ 9.578303]], dtype=float32)]\n",
      "1500 0.010794317 [array([[ 6.242753 , -6.8029747],\n",
      "       [-6.7085137,  7.1441584]], dtype=float32), array([[10.232743],\n",
      "       [ 9.810454]], dtype=float32)]\n",
      "1600 0.009590316 [array([[ 6.32908  , -6.8915577],\n",
      "       [-6.7941732,  7.2311172]], dtype=float32), array([[10.449962],\n",
      "       [10.03    ]], dtype=float32)]\n",
      "1700 0.008573185 [array([[ 6.4094553, -6.9740477],\n",
      "       [-6.8739595,  7.312116 ]], dtype=float32), array([[10.656366],\n",
      "       [10.238612]], dtype=float32)]\n",
      "1800 0.0077051977 [array([[ 6.484699 , -7.051277 ],\n",
      "       [-6.9486804,  7.387974 ]], dtype=float32), array([[10.853316],\n",
      "       [10.437652]], dtype=float32)]\n",
      "1900 0.006957829 [array([[ 6.5554795, -7.12393  ],\n",
      "       [-7.0189905,  7.459351 ]], dtype=float32), array([[11.041933],\n",
      "       [10.628246]], dtype=float32)]\n",
      "2000 0.006309393 [array([[ 6.6223445, -7.1925664],\n",
      "       [-7.0854316,  7.5267982]], dtype=float32), array([[11.223158],\n",
      "       [10.811347]], dtype=float32)]\n",
      "2100 0.005742714 [array([[ 6.685749 , -7.2576523],\n",
      "       [-7.148453 ,  7.59077  ]], dtype=float32), array([[11.397784],\n",
      "       [10.987764]], dtype=float32)]\n",
      "2200 0.005244485 [array([[ 6.7460775, -7.319577 ],\n",
      "       [-7.208433 ,  7.6516523]], dtype=float32), array([[11.566492],\n",
      "       [11.158178]], dtype=float32)]\n",
      "2300 0.0048038983 [array([[ 6.8036537, -7.3786774],\n",
      "       [-7.2656927,  7.7097683]], dtype=float32), array([[11.729868],\n",
      "       [11.323187]], dtype=float32)]\n",
      "2400 0.004412344 [array([[ 6.8587594, -7.435237 ],\n",
      "       [-7.320504 ,  7.765398 ]], dtype=float32), array([[11.888419],\n",
      "       [11.483295]], dtype=float32)]\n",
      "2500 0.004062689 [array([[ 6.91163  , -7.489502 ],\n",
      "       [-7.3731093,  7.818782 ]], dtype=float32), array([[12.042592],\n",
      "       [11.638964]], dtype=float32)]\n",
      "2600 0.0037491736 [array([[ 6.962477, -7.541683],\n",
      "       [-7.423709,  7.870127]], dtype=float32), array([[12.19277 ],\n",
      "       [11.790581]], dtype=float32)]\n",
      "2700 0.0034669796 [array([[ 7.0114794, -7.5919704],\n",
      "       [-7.4724846,  7.919617 ]], dtype=float32), array([[12.339302 ],\n",
      "       [11.9384985]], dtype=float32)]\n",
      "2800 0.003212058 [array([[ 7.0587955, -7.6405253],\n",
      "       [-7.5195923,  7.9674115]], dtype=float32), array([[12.482494],\n",
      "       [12.083018]], dtype=float32)]\n",
      "2900 0.0029809962 [array([[ 7.104568 , -7.687491 ],\n",
      "       [-7.5651712,  8.013649 ]], dtype=float32), array([[12.622612],\n",
      "       [12.224427]], dtype=float32)]\n",
      "3000 0.0027709822 [array([[ 7.1489196, -7.7329946],\n",
      "       [-7.609344 ,  8.0584545]], dtype=float32), array([[12.759907],\n",
      "       [12.362965]], dtype=float32)]\n",
      "3100 0.002579568 [array([[ 7.1919622, -7.777151 ],\n",
      "       [-7.652218 ,  8.101942 ]], dtype=float32), array([[12.894589],\n",
      "       [12.498854]], dtype=float32)]\n",
      "3200 0.0024046064 [array([[ 7.233792 , -7.8200593],\n",
      "       [-7.693892 ,  8.144206 ]], dtype=float32), array([[13.026862 ],\n",
      "       [12.6322975]], dtype=float32)]\n",
      "3300 0.0022443123 [array([[ 7.274499 , -7.8618126],\n",
      "       [-7.7344537,  8.185339 ]], dtype=float32), array([[13.156905],\n",
      "       [12.763471]], dtype=float32)]\n",
      "3400 0.0020971396 [array([[ 7.314162, -7.902492],\n",
      "       [-7.773981,  8.225419]], dtype=float32), array([[13.284877],\n",
      "       [12.892542]], dtype=float32)]\n",
      "3500 0.001961769 [array([[ 7.352852 , -7.9421716],\n",
      "       [-7.812545 ,  8.264521 ]], dtype=float32), array([[13.410925],\n",
      "       [13.019661]], dtype=float32)]\n",
      "3600 0.0018369715 [array([[ 7.3906364, -7.980915 ],\n",
      "       [-7.8502088,  8.302705 ]], dtype=float32), array([[13.535187],\n",
      "       [13.144961]], dtype=float32)]\n",
      "3700 0.0017217281 [array([[ 7.4275703, -8.018786 ],\n",
      "       [-7.8870325,  8.340034 ]], dtype=float32), array([[13.657784],\n",
      "       [13.26857 ]], dtype=float32)]\n",
      "3800 0.0016151398 [array([[ 7.463711 , -8.055838 ],\n",
      "       [-7.9230676,  8.376559 ]], dtype=float32), array([[13.778829],\n",
      "       [13.390599]], dtype=float32)]\n",
      "3900 0.0015163682 [array([[ 7.4991055, -8.09212  ],\n",
      "       [-7.958363 ,  8.412334 ]], dtype=float32), array([[13.898424],\n",
      "       [13.511158]], dtype=float32)]\n",
      "4000 0.0014247242 [array([[ 7.5337973, -8.127679 ],\n",
      "       [-7.9929643,  8.447398 ]], dtype=float32), array([[14.016665],\n",
      "       [13.630341]], dtype=float32)]\n",
      "4100 0.0013396095 [array([[ 7.567828, -8.162559],\n",
      "       [-8.026908,  8.481797]], dtype=float32), array([[14.133643],\n",
      "       [13.748235]], dtype=float32)]\n",
      "4200 0.0012603657 [array([[ 7.6012373, -8.196796 ],\n",
      "       [-8.060234 ,  8.515567 ]], dtype=float32), array([[14.249437],\n",
      "       [13.864925]], dtype=float32)]\n",
      "4300 0.0011866036 [array([[ 7.634057, -8.230428],\n",
      "       [-8.092978,  8.548741]], dtype=float32), array([[14.364121],\n",
      "       [13.980484]], dtype=float32)]\n",
      "4400 0.0011178144 [array([[ 7.666319, -8.263484],\n",
      "       [-8.125167,  8.581354]], dtype=float32), array([[14.477767],\n",
      "       [14.094987]], dtype=float32)]\n",
      "4500 0.0010535648 [array([[ 7.698053, -8.295999],\n",
      "       [-8.156836,  8.613435]], dtype=float32), array([[14.590436],\n",
      "       [14.208499]], dtype=float32)]\n",
      "4600 0.0009935705 [array([[ 7.729288, -8.327996],\n",
      "       [-8.188007,  8.645012]], dtype=float32), array([[14.70219 ],\n",
      "       [14.321079]], dtype=float32)]\n",
      "4700 0.00093739806 [array([[ 7.760048, -8.359506],\n",
      "       [-8.218708,  8.676106]], dtype=float32), array([[14.813087],\n",
      "       [14.432786]], dtype=float32)]\n",
      "4800 0.00088485295 [array([[ 7.790355, -8.390548],\n",
      "       [-8.248958,  8.706743]], dtype=float32), array([[14.923176],\n",
      "       [14.543669]], dtype=float32)]\n",
      "4900 0.00083560665 [array([[ 7.8202324, -8.421149 ],\n",
      "       [-8.278784 ,  8.736949 ]], dtype=float32), array([[15.032508],\n",
      "       [14.653779]], dtype=float32)]\n",
      "5000 0.0007894051 [array([[ 7.849699 , -8.4513235],\n",
      "       [-8.308202 ,  8.766735 ]], dtype=float32), array([[15.141127],\n",
      "       [14.763162]], dtype=float32)]\n",
      "5100 0.000746024 [array([[ 7.8787746, -8.481094 ],\n",
      "       [-8.337231 ,  8.796127 ]], dtype=float32), array([[15.249074],\n",
      "       [14.871863]], dtype=float32)]\n",
      "5200 0.000705329 [array([[ 7.907476, -8.510482],\n",
      "       [-8.365889,  8.825144]], dtype=float32), array([[15.356389],\n",
      "       [14.979918]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300 0.00066705124 [array([[ 7.935819, -8.539501],\n",
      "       [-8.39419 ,  8.853798]], dtype=float32), array([[15.463109],\n",
      "       [15.087366]], dtype=float32)]\n",
      "5400 0.00063107116 [array([[ 7.9638205, -8.568164 ],\n",
      "       [-8.422157 ,  8.882103 ]], dtype=float32), array([[15.569275],\n",
      "       [15.194242]], dtype=float32)]\n",
      "5500 0.00059719477 [array([[ 7.991493, -8.596491],\n",
      "       [-8.449792,  8.910081]], dtype=float32), array([[15.674908],\n",
      "       [15.300581]], dtype=float32)]\n",
      "5600 0.00056534726 [array([[ 8.018848, -8.62449 ],\n",
      "       [-8.477118,  8.937737]], dtype=float32), array([[15.780047],\n",
      "       [15.406411]], dtype=float32)]\n",
      "5700 0.0005352899 [array([[ 8.045903, -8.65218 ],\n",
      "       [-8.504144,  8.965088]], dtype=float32), array([[15.884717],\n",
      "       [15.511765]], dtype=float32)]\n",
      "5800 0.00050699257 [array([[ 8.07267  , -8.67957  ],\n",
      "       [-8.530881 ,  8.9921465]], dtype=float32), array([[15.98895 ],\n",
      "       [15.616667]], dtype=float32)]\n",
      "5900 0.00048027642 [array([[ 8.099155, -8.706672],\n",
      "       [-8.557341,  9.018921]], dtype=float32), array([[16.092764],\n",
      "       [15.721142]], dtype=float32)]\n",
      "6000 0.00045509645 [array([[ 8.125374, -8.733494],\n",
      "       [-8.583534,  9.045429]], dtype=float32), array([[16.19618 ],\n",
      "       [15.825219]], dtype=float32)]\n",
      "6100 0.00043131848 [array([[ 8.151329, -8.760049],\n",
      "       [-8.60947 ,  9.071665]], dtype=float32), array([[16.299238],\n",
      "       [15.928915]], dtype=float32)]\n",
      "6200 0.00040891254 [array([[ 8.177038, -8.786348],\n",
      "       [-8.635155,  9.097654]], dtype=float32), array([[16.401945],\n",
      "       [16.03224 ]], dtype=float32)]\n",
      "6300 0.00038768476 [array([[ 8.202503, -8.812394],\n",
      "       [-8.660605,  9.123399]], dtype=float32), array([[16.504309],\n",
      "       [16.135246]], dtype=float32)]\n",
      "6400 0.0003676649 [array([[ 8.227735, -8.838202],\n",
      "       [-8.685819,  9.148904]], dtype=float32), array([[16.606369],\n",
      "       [16.237938]], dtype=float32)]\n",
      "6500 0.00034874846 [array([[ 8.252738, -8.863772],\n",
      "       [-8.710809,  9.174183]], dtype=float32), array([[16.708132],\n",
      "       [16.340311]], dtype=float32)]\n",
      "6600 0.00033083116 [array([[ 8.27753  , -8.889124 ],\n",
      "       [-8.735586 ,  9.1992445]], dtype=float32), array([[16.809645],\n",
      "       [16.442425]], dtype=float32)]\n",
      "6700 0.00031388304 [array([[ 8.30211 , -8.914255],\n",
      "       [-8.760155,  9.224084]], dtype=float32), array([[16.910868],\n",
      "       [16.544245]], dtype=float32)]\n",
      "6800 0.00029785934 [array([[ 8.326485, -8.939171],\n",
      "       [-8.784514,  9.248717]], dtype=float32), array([[17.011858],\n",
      "       [16.645817]], dtype=float32)]\n",
      "6900 0.0002826855 [array([[ 8.3506565, -8.963882 ],\n",
      "       [-8.808678 ,  9.2731495]], dtype=float32), array([[17.112621],\n",
      "       [16.747158]], dtype=float32)]\n",
      "7000 0.0002683317 [array([[ 8.374637, -8.988395],\n",
      "       [-8.83265 ,  9.297393]], dtype=float32), array([[17.213171],\n",
      "       [16.848274]], dtype=float32)]\n",
      "7100 0.00025473826 [array([[ 8.398429, -9.012715],\n",
      "       [-8.856439,  9.321448]], dtype=float32), array([[17.313494],\n",
      "       [16.949194]], dtype=float32)]\n",
      "7200 0.00024184554 [array([[ 8.422035, -9.036848],\n",
      "       [-8.880043,  9.345316]], dtype=float32), array([[17.41363 ],\n",
      "       [17.049894]], dtype=float32)]\n",
      "7300 0.0002296386 [array([[ 8.445466, -9.060798],\n",
      "       [-8.90347 ,  9.369008]], dtype=float32), array([[17.513575],\n",
      "       [17.15041 ]], dtype=float32)]\n",
      "7400 0.00021810248 [array([[ 8.468724, -9.084571],\n",
      "       [-8.926726,  9.392517]], dtype=float32), array([[17.613344],\n",
      "       [17.250736]], dtype=float32)]\n",
      "7500 0.00020710306 [array([[ 8.491817 , -9.1081705],\n",
      "       [-8.949819 ,  9.415861 ]], dtype=float32), array([[17.71295 ],\n",
      "       [17.350893]], dtype=float32)]\n",
      "7600 0.00019672974 [array([[ 8.514756, -9.131594],\n",
      "       [-8.97275 ,  9.439036]], dtype=float32), array([[17.812443],\n",
      "       [17.450882]], dtype=float32)]\n",
      "7700 0.00018689307 [array([[ 8.537529, -9.154857],\n",
      "       [-8.995517,  9.462054]], dtype=float32), array([[17.911798],\n",
      "       [17.55073 ]], dtype=float32)]\n",
      "7800 0.00017753342 [array([[ 8.560148, -9.177964],\n",
      "       [-9.018139,  9.484902]], dtype=float32), array([[18.01098],\n",
      "       [17.65045]], dtype=float32)]\n",
      "7900 0.00016868059 [array([[ 8.58261 , -9.200906],\n",
      "       [-9.040603,  9.507606]], dtype=float32), array([[18.110043],\n",
      "       [17.750013]], dtype=float32)]\n",
      "8000 0.00016026004 [array([[ 8.604927, -9.223698],\n",
      "       [-9.062923,  9.530157]], dtype=float32), array([[18.209024],\n",
      "       [17.849438]], dtype=float32)]\n",
      "8100 0.00015233137 [array([[ 8.627097, -9.246344],\n",
      "       [-9.085099,  9.552573]], dtype=float32), array([[18.307825],\n",
      "       [17.94881 ]], dtype=float32)]\n",
      "8200 0.00014473063 [array([[ 8.649122, -9.26884 ],\n",
      "       [-9.107138,  9.57484 ]], dtype=float32), array([[18.40655 ],\n",
      "       [18.048016]], dtype=float32)]\n",
      "8300 0.00013754726 [array([[ 8.671009, -9.291199],\n",
      "       [-9.129032,  9.596966]], dtype=float32), array([[18.50516 ],\n",
      "       [18.147177]], dtype=float32)]\n",
      "8400 0.0001307365 [array([[ 8.692767, -9.313413],\n",
      "       [-9.150804,  9.618952]], dtype=float32), array([[18.60369 ],\n",
      "       [18.246168]], dtype=float32)]\n",
      "8500 0.00012426857 [array([[ 8.714383, -9.335491],\n",
      "       [-9.172426,  9.640811]], dtype=float32), array([[18.702108],\n",
      "       [18.34514 ]], dtype=float32)]\n",
      "8600 0.00011811364 [array([[ 8.735879, -9.357439],\n",
      "       [-9.193929,  9.662524]], dtype=float32), array([[18.800495],\n",
      "       [18.443941]], dtype=float32)]\n",
      "8700 0.00011228661 [array([[ 8.757246, -9.379246],\n",
      "       [-9.21531 ,  9.684117]], dtype=float32), array([[18.898724],\n",
      "       [18.542742]], dtype=float32)]\n",
      "8800 0.00010675766 [array([[ 8.778482, -9.400931],\n",
      "       [-9.236554,  9.705579]], dtype=float32), array([[18.996952],\n",
      "       [18.641373]], dtype=float32)]\n",
      "8900 0.000101482095 [array([[ 8.799601, -9.422488],\n",
      "       [-9.257682,  9.726914]], dtype=float32), array([[19.09508 ],\n",
      "       [18.739983]], dtype=float32)]\n",
      "9000 9.648972e-05 [array([[ 8.820603, -9.443914],\n",
      "       [-9.278695,  9.748132]], dtype=float32), array([[19.193117],\n",
      "       [18.838554]], dtype=float32)]\n",
      "9100 9.17507e-05 [array([[ 8.841476, -9.465224],\n",
      "       [-9.29959 ,  9.769236]], dtype=float32), array([[19.291155],\n",
      "       [18.936974]], dtype=float32)]\n",
      "9200 8.723523e-05 [array([[ 8.862236, -9.486419],\n",
      "       [-9.320361,  9.790216]], dtype=float32), array([[19.389118],\n",
      "       [19.035393]], dtype=float32)]\n",
      "9300 8.292843e-05 [array([[ 8.882884, -9.507487],\n",
      "       [-9.341022,  9.811074]], dtype=float32), array([[19.486965],\n",
      "       [19.133812]], dtype=float32)]\n",
      "9400 7.886008e-05 [array([[ 8.903426, -9.528439],\n",
      "       [-9.361573,  9.831823]], dtype=float32), array([[19.584812],\n",
      "       [19.232052]], dtype=float32)]\n",
      "9500 7.498548e-05 [array([[ 8.923856, -9.549279],\n",
      "       [-9.382017,  9.852462]], dtype=float32), array([[19.68266],\n",
      "       [19.33028]], dtype=float32)]\n",
      "9600 7.133442e-05 [array([[ 8.944176, -9.57001 ],\n",
      "       [-9.402355,  9.87299 ]], dtype=float32), array([[19.780436],\n",
      "       [19.428509]], dtype=float32)]\n",
      "9700 6.7817506e-05 [array([[ 8.964386 , -9.590632 ],\n",
      "       [-9.422586 ,  9.8934145]], dtype=float32), array([[19.878092],\n",
      "       [19.52673 ]], dtype=float32)]\n",
      "9800 6.450922e-05 [array([[ 8.98449 , -9.611148],\n",
      "       [-9.442713,  9.913729]], dtype=float32), array([[19.975748],\n",
      "       [19.624792]], dtype=float32)]\n",
      "9900 6.136488e-05 [array([[ 9.004492, -9.631549],\n",
      "       [-9.462732,  9.933935]], dtype=float32), array([[20.073404],\n",
      "       [19.72283 ]], dtype=float32)]\n",
      "10000 5.8339763e-05 [array([[ 9.024394, -9.651845],\n",
      "       [-9.482652,  9.95404 ]], dtype=float32), array([[20.17106 ],\n",
      "       [19.820868]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[6.1310318e-05]\n",
      " [9.9993694e-01]\n",
      " [9.9995077e-01]\n",
      " [5.9751477e-05]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "## tensorBoard execution using  Lab 9 XOR\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)  # record summary.histogram with W1\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)   # record summary.histogram with b1\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)  # record summary.histogram with layer1\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)   # record summary.histogram with W2\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)    # record summary.histogram with b2\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis) # record summarry hypothesis\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)   # record summary.scala with cost\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()  # 2. merge all summaries \n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_logs_r0_01\")\n",
    "    writer.add_graph(sess.graph)  # 3. create writer and add graph   \n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)    # 4. run summary \n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7539022 [array([[ 0.7988674 ,  0.6801188 ],\n",
      "       [-1.2198634 , -0.30361032]], dtype=float32), array([[ 1.3752297 ],\n",
      "       [-0.78823847]], dtype=float32)]\n",
      "100 0.6958442 [array([[ 0.671669  ,  0.71368533],\n",
      "       [-1.2917174 , -0.24467795]], dtype=float32), array([[ 1.1212678 ],\n",
      "       [-0.90971714]], dtype=float32)]\n",
      "200 0.694039 [array([[ 0.64527303,  0.7046099 ],\n",
      "       [-1.318939  , -0.22392064]], dtype=float32), array([[ 1.0992552],\n",
      "       [-0.8951719]], dtype=float32)]\n",
      "300 0.6924366 [array([[ 0.645278 ,  0.6960101],\n",
      "       [-1.3529738, -0.206362 ]], dtype=float32), array([[ 1.090277 ],\n",
      "       [-0.8809227]], dtype=float32)]\n",
      "400 0.69080454 [array([[ 0.66653323,  0.6891593 ],\n",
      "       [-1.3948005 , -0.19111179]], dtype=float32), array([[ 1.0908598 ],\n",
      "       [-0.86969197]], dtype=float32)]\n",
      "500 0.6889793 [array([[ 0.706353  ,  0.68438065],\n",
      "       [-1.4450662 , -0.17811842]], dtype=float32), array([[ 1.102191  ],\n",
      "       [-0.86151737]], dtype=float32)]\n",
      "600 0.68681204 [array([[ 0.7632088 ,  0.68197995],\n",
      "       [-1.5046262 , -0.16744027]], dtype=float32), array([[ 1.1260484 ],\n",
      "       [-0.85649955]], dtype=float32)]\n",
      "700 0.6841461 [array([[ 0.8364961,  0.682307 ],\n",
      "       [-1.5744196, -0.1592362]], dtype=float32), array([[ 1.1645079 ],\n",
      "       [-0.85485953]], dtype=float32)]\n",
      "800 0.68080217 [array([[ 0.9262921 ,  0.6857974 ],\n",
      "       [-1.6554022 , -0.15377551]], dtype=float32), array([[ 1.219755 ],\n",
      "       [-0.8569454]], dtype=float32)]\n",
      "900 0.67657316 [array([[ 1.0330845 ,  0.69301593],\n",
      "       [-1.7484908 , -0.15145336]], dtype=float32), array([[ 1.2938781 ],\n",
      "       [-0.86324763]], dtype=float32)]\n",
      "1000 0.67122906 [array([[ 1.1574563 ,  0.70470023],\n",
      "       [-1.8544798 , -0.15281102]], dtype=float32), array([[ 1.3886284],\n",
      "       [-0.8744256]], dtype=float32)]\n",
      "1100 0.6645359 [array([[ 1.2997088 ,  0.7218018 ],\n",
      "       [-1.9739141 , -0.15856187]], dtype=float32), array([[ 1.5051457 ],\n",
      "       [-0.89133704]], dtype=float32)]\n",
      "1200 0.6562889 [array([[ 1.459459  ,  0.7455183 ],\n",
      "       [-2.1069145 , -0.16962206]], dtype=float32), array([[ 1.6436868],\n",
      "       [-0.9150648]], dtype=float32)]\n",
      "1300 0.64635646 [array([[ 1.635309  ,  0.7773058 ],\n",
      "       [-2.2529743 , -0.18714131]], dtype=float32), array([[ 1.8034167],\n",
      "       [-0.94693  ]], dtype=float32)]\n",
      "1400 0.63471764 [array([[ 1.8247268 ,  0.8188663 ],\n",
      "       [-2.4107943 , -0.21252976]], dtype=float32), array([[ 1.982346],\n",
      "       [-0.988494]], dtype=float32)]\n",
      "1500 0.6214698 [array([[ 2.0242445 ,  0.87210923],\n",
      "       [-2.5782278 , -0.24747993]], dtype=float32), array([[ 2.1775007],\n",
      "       [-1.0415565]], dtype=float32)]\n",
      "1600 0.60678446 [array([[ 2.2299707 ,  0.9390989 ],\n",
      "       [-2.7524273 , -0.29400012]], dtype=float32), array([[ 2.385337 ],\n",
      "       [-1.1081707]], dtype=float32)]\n",
      "1700 0.59081197 [array([[ 2.4382195 ,  1.0220114 ],\n",
      "       [-2.9301887 , -0.35449192]], dtype=float32), array([[ 2.6023211],\n",
      "       [-1.1906685]], dtype=float32)]\n",
      "1800 0.5735615 [array([[ 2.6460273,  1.1230904],\n",
      "       [-3.1083782, -0.4319004]], dtype=float32), array([[ 2.8255026],\n",
      "       [-1.2917072]], dtype=float32)]\n",
      "1900 0.5547905 [array([[ 2.8513803,  1.2445759],\n",
      "       [-3.2842975, -0.5299181]], dtype=float32), array([[ 3.052883 ],\n",
      "       [-1.4143035]], dtype=float32)]\n",
      "2000 0.53393596 [array([[ 3.053097 ,  1.3885086],\n",
      "       [-3.4558659, -0.6531137]], dtype=float32), array([[ 3.2834744],\n",
      "       [-1.5618594]], dtype=float32)]\n",
      "2100 0.5101246 [array([[ 3.2504313,  1.5562978],\n",
      "       [-3.6216145, -0.8066704]], dtype=float32), array([[ 3.5170052],\n",
      "       [-1.7380936]], dtype=float32)]\n",
      "2200 0.48234087 [array([[ 3.4425383 ,  1.7479419 ],\n",
      "       [-3.7805455 , -0.99522465]], dtype=float32), array([[ 3.7533436],\n",
      "       [-1.9466529]], dtype=float32)]\n",
      "2300 0.44984132 [array([[ 3.6280715,  1.9610723],\n",
      "       [-3.9319441, -1.2204902]], dtype=float32), array([[ 3.9918833],\n",
      "       [-2.1899748]], dtype=float32)]\n",
      "2400 0.41275072 [array([[ 3.8052044,  2.1904552],\n",
      "       [-4.0752544, -1.4784237]], dtype=float32), array([[ 4.2312236],\n",
      "       [-2.4673057]], dtype=float32)]\n",
      "2500 0.3724525 [array([[ 3.9720516,  2.4285593],\n",
      "       [-4.2100306, -1.7581936]], dtype=float32), array([[ 4.4693065],\n",
      "       [-2.7729063]], dtype=float32)]\n",
      "2600 0.3313274 [array([[ 4.127145 ,  2.667004 ],\n",
      "       [-4.3359613, -2.0447464]], dtype=float32), array([[ 4.703768 ],\n",
      "       [-3.0962682]], dtype=float32)]\n",
      "2700 0.29190764 [array([[ 4.2696815,  2.898184 ],\n",
      "       [-4.4529204, -2.3236113]], dtype=float32), array([[ 4.9322886],\n",
      "       [-3.4247894]], dtype=float32)]\n",
      "2800 0.25606006 [array([[ 4.3995347,  3.1164253],\n",
      "       [-4.561016 , -2.5845597]], dtype=float32), array([[ 5.1528683],\n",
      "       [-3.7471333]], dtype=float32)]\n",
      "2900 0.22468187 [array([[ 4.5171614,  3.3184152],\n",
      "       [-4.6605887, -2.8224585]], dtype=float32), array([[ 5.364031 ],\n",
      "       [-4.0552683]], dtype=float32)]\n",
      "3000 0.19786675 [array([[ 4.6234245,  3.502949 ],\n",
      "       [-4.752163 , -3.0361452]], dtype=float32), array([[ 5.564906],\n",
      "       [-4.344725]], dtype=float32)]\n",
      "3100 0.17523663 [array([[ 4.719409 ,  3.6703115],\n",
      "       [-4.836381 , -3.2268152]], dtype=float32), array([[ 5.7551665],\n",
      "       [-4.613844 ]], dtype=float32)]\n",
      "3200 0.15622242 [array([[ 4.8062506,  3.8216534],\n",
      "       [-4.9139175, -3.3967357]], dtype=float32), array([[ 5.934911],\n",
      "       [-4.862758]], dtype=float32)]\n",
      "3300 0.14023173 [array([[ 4.8850565,  3.95851  ],\n",
      "       [-4.985447 , -3.5484731]], dtype=float32), array([[ 6.104518],\n",
      "       [-5.092593]], dtype=float32)]\n",
      "3400 0.12672827 [array([[ 4.9568415,  4.082506 ],\n",
      "       [-5.0516014, -3.6844974]], dtype=float32), array([[ 6.2645364],\n",
      "       [-5.3049154]], dtype=float32)]\n",
      "3500 0.11525792 [array([[ 5.0224953,  4.1951914],\n",
      "       [-5.1129546, -3.8070166]], dtype=float32), array([[ 6.4156003],\n",
      "       [-5.501411 ]], dtype=float32)]\n",
      "3600 0.10544856 [array([[ 5.0827985,  4.2979736],\n",
      "       [-5.1700134, -3.9179351]], dtype=float32), array([[ 6.558356],\n",
      "       [-5.683722]], dtype=float32)]\n",
      "3700 0.09700038 [array([[ 5.1384068,  4.3920865],\n",
      "       [-5.223237 , -4.018866 ]], dtype=float32), array([[ 6.6934476],\n",
      "       [-5.853364 ]], dtype=float32)]\n",
      "3800 0.08967343 [array([[ 5.189897 ,  4.4786034],\n",
      "       [-5.2730236, -4.1111627]], dtype=float32), array([[ 6.8214817],\n",
      "       [-6.0116987]], dtype=float32)]\n",
      "3900 0.08327566 [array([[ 5.237753 ,  4.558449 ],\n",
      "       [-5.3197265, -4.1959615]], dtype=float32), array([[ 6.9430256],\n",
      "       [-6.1599298]], dtype=float32)]\n",
      "4000 0.07765331 [array([[ 5.282392 ,  4.63241  ],\n",
      "       [-5.363648 , -4.2742133]], dtype=float32), array([[ 7.0586023],\n",
      "       [-6.2991076]], dtype=float32)]\n",
      "4100 0.07268219 [array([[ 5.3241673,  4.701171 ],\n",
      "       [-5.4050617, -4.34672  ]], dtype=float32), array([[ 7.16869 ],\n",
      "       [-6.430157]], dtype=float32)]\n",
      "4200 0.06826201 [array([[ 5.363381 ,  4.765296 ],\n",
      "       [-5.4441967, -4.4141564]], dtype=float32), array([[ 7.2737265],\n",
      "       [-6.553883 ]], dtype=float32)]\n",
      "4300 0.064310886 [array([[ 5.4003005,  4.825292 ],\n",
      "       [-5.4812636, -4.477101 ]], dtype=float32), array([[ 7.3740873],\n",
      "       [-6.670991 ]], dtype=float32)]\n",
      "4400 0.060761552 [array([[ 5.4351525,  4.8815904],\n",
      "       [-5.5164433, -4.5360384]], dtype=float32), array([[ 7.4701357],\n",
      "       [-6.782097 ]], dtype=float32)]\n",
      "4500 0.057558615 [array([[ 5.468133 ,  4.934562 ],\n",
      "       [-5.5498977, -4.591391 ]], dtype=float32), array([[ 7.5621915],\n",
      "       [-6.8877373]], dtype=float32)]\n",
      "4600 0.054655917 [array([[ 5.499414 ,  4.98453  ],\n",
      "       [-5.5817704, -4.6435204]], dtype=float32), array([[ 7.6505456],\n",
      "       [-6.98839  ]], dtype=float32)]\n",
      "4700 0.052014843 [array([[ 5.529149 ,  5.031776 ],\n",
      "       [-5.6121883, -4.6927395]], dtype=float32), array([[ 7.7354574],\n",
      "       [-7.084478 ]], dtype=float32)]\n",
      "4800 0.049602933 [array([[ 5.55747  ,  5.0765476],\n",
      "       [-5.6412654, -4.739321 ]], dtype=float32), array([[ 7.817166 ],\n",
      "       [-7.1763716]], dtype=float32)]\n",
      "4900 0.047392774 [array([[ 5.584492 ,  5.119062 ],\n",
      "       [-5.669103 , -4.7835035]], dtype=float32), array([[ 7.895887 ],\n",
      "       [-7.2644014]], dtype=float32)]\n",
      "5000 0.04536082 [array([[ 5.610321 ,  5.1595116],\n",
      "       [-5.695793 , -4.8254967]], dtype=float32), array([[ 7.971818 ],\n",
      "       [-7.3488626]], dtype=float32)]\n",
      "5100 0.043487232 [array([[ 5.63505  ,  5.198066 ],\n",
      "       [-5.7214184, -4.8654847]], dtype=float32), array([[ 8.045136 ],\n",
      "       [-7.4300194]], dtype=float32)]\n",
      "5200 0.041754756 [array([[ 5.6587605,  5.2348766],\n",
      "       [-5.7460504, -4.903632 ]], dtype=float32), array([[ 8.116003 ],\n",
      "       [-7.5081105]], dtype=float32)]\n",
      "5300 0.04014849 [array([[ 5.681528 ,  5.270076 ],\n",
      "       [-5.7697577, -4.940082 ]], dtype=float32), array([[ 8.184571],\n",
      "       [-7.583347]], dtype=float32)]\n",
      "5400 0.038655564 [array([[ 5.7034197,  5.303787 ],\n",
      "       [-5.7926016, -4.974966 ]], dtype=float32), array([[ 8.250976],\n",
      "       [-7.655922]], dtype=float32)]\n",
      "5500 0.037264757 [array([[ 5.7244945,  5.336118 ],\n",
      "       [-5.814636 , -5.0084014]], dtype=float32), array([[ 8.315342],\n",
      "       [-7.72601 ]], dtype=float32)]\n",
      "5600 0.035966214 [array([[ 5.7448063,  5.3671665],\n",
      "       [-5.835913 , -5.0404897]], dtype=float32), array([[ 8.377787],\n",
      "       [-7.793771]], dtype=float32)]\n",
      "5700 0.03475129 [array([[ 5.764405 ,  5.39702  ],\n",
      "       [-5.8564777, -5.0713267]], dtype=float32), array([[ 8.438415],\n",
      "       [-7.859348]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 0.03361243 [array([[ 5.7833366,  5.4257593],\n",
      "       [-5.876374 , -5.1009974]], dtype=float32), array([[ 8.497322 ],\n",
      "       [-7.9228725]], dtype=float32)]\n",
      "5900 0.032542817 [array([[ 5.801642 ,  5.4534564],\n",
      "       [-5.8956375, -5.129578 ]], dtype=float32), array([[ 8.554606 ],\n",
      "       [-7.9844666]], dtype=float32)]\n",
      "6000 0.031536568 [array([[ 5.819358 ,  5.4801764],\n",
      "       [-5.914306 , -5.1571383]], dtype=float32), array([[ 8.610341],\n",
      "       [-8.044239]], dtype=float32)]\n",
      "6100 0.030588254 [array([[ 5.836518,  5.505981],\n",
      "       [-5.932412, -5.183743]], dtype=float32), array([[ 8.66461 ],\n",
      "       [-8.102289]], dtype=float32)]\n",
      "6200 0.029693164 [array([[ 5.853154 ,  5.5309243],\n",
      "       [-5.949986 , -5.2094502]], dtype=float32), array([[ 8.7174835],\n",
      "       [-8.158716 ]], dtype=float32)]\n",
      "6300 0.028847102 [array([[ 5.869296 ,  5.555055 ],\n",
      "       [-5.9670553, -5.234313 ]], dtype=float32), array([[ 8.769032],\n",
      "       [-8.2136  ]], dtype=float32)]\n",
      "6400 0.028046183 [array([[ 5.8849688,  5.578424 ],\n",
      "       [-5.983647 , -5.2583804]], dtype=float32), array([[ 8.819315],\n",
      "       [-8.267023]], dtype=float32)]\n",
      "6500 0.027286937 [array([[ 5.9001994,  5.6010704],\n",
      "       [-5.999783 , -5.2816963]], dtype=float32), array([[ 8.868396],\n",
      "       [-8.319061]], dtype=float32)]\n",
      "6600 0.026566334 [array([[ 5.91501  ,  5.6230345],\n",
      "       [-6.015487 , -5.304303 ]], dtype=float32), array([[ 8.916321],\n",
      "       [-8.36978 ]], dtype=float32)]\n",
      "6700 0.025881505 [array([[ 5.9294205,  5.6443543],\n",
      "       [-6.0307813, -5.326239 ]], dtype=float32), array([[ 8.963146],\n",
      "       [-8.419242]], dtype=float32)]\n",
      "6800 0.025229974 [array([[ 5.943453 ,  5.665061 ],\n",
      "       [-6.045684 , -5.3475394]], dtype=float32), array([[ 9.008919],\n",
      "       [-8.467508]], dtype=float32)]\n",
      "6900 0.024609344 [array([[ 5.957122 ,  5.6851873],\n",
      "       [-6.0602107, -5.368236 ]], dtype=float32), array([[ 9.053683],\n",
      "       [-8.514635]], dtype=float32)]\n",
      "7000 0.02401754 [array([[ 5.970447 ,  5.7047625],\n",
      "       [-6.074383 , -5.3883605]], dtype=float32), array([[ 9.097483],\n",
      "       [-8.560672]], dtype=float32)]\n",
      "7100 0.02345264 [array([[ 5.9834447,  5.7238116],\n",
      "       [-6.0882134, -5.40794  ]], dtype=float32), array([[ 9.140356],\n",
      "       [-8.605669]], dtype=float32)]\n",
      "7200 0.022912856 [array([[ 5.9961276,  5.7423606],\n",
      "       [-6.1017184, -5.427002 ]], dtype=float32), array([[ 9.182341],\n",
      "       [-8.649668]], dtype=float32)]\n",
      "7300 0.022396646 [array([[ 6.008512 ,  5.7604337],\n",
      "       [-6.114912 , -5.4455705]], dtype=float32), array([[ 9.223471],\n",
      "       [-8.692715]], dtype=float32)]\n",
      "7400 0.021902483 [array([[ 6.0206084,  5.778052 ],\n",
      "       [-6.1278057, -5.463667 ]], dtype=float32), array([[ 9.2637825],\n",
      "       [-8.734846 ]], dtype=float32)]\n",
      "7500 0.021429015 [array([[ 6.0324316,  5.7952356],\n",
      "       [-6.140413 , -5.481314 ]], dtype=float32), array([[ 9.303302],\n",
      "       [-8.776102]], dtype=float32)]\n",
      "7600 0.020974983 [array([[ 6.0439916,  5.812005 ],\n",
      "       [-6.1527443, -5.4985313]], dtype=float32), array([[ 9.342064],\n",
      "       [-8.816517]], dtype=float32)]\n",
      "7700 0.020539287 [array([[ 6.0553   ,  5.8283772],\n",
      "       [-6.164813 , -5.5153375]], dtype=float32), array([[ 9.380093],\n",
      "       [-8.856121]], dtype=float32)]\n",
      "7800 0.020120762 [array([[ 6.0663652,  5.84437  ],\n",
      "       [-6.176627 , -5.531751 ]], dtype=float32), array([[ 9.417418],\n",
      "       [-8.894948]], dtype=float32)]\n",
      "7900 0.019718504 [array([[ 6.077197 ,  5.8599973],\n",
      "       [-6.1881976, -5.5477886]], dtype=float32), array([[ 9.4540615],\n",
      "       [-8.933028 ]], dtype=float32)]\n",
      "8000 0.019331548 [array([[ 6.087807 ,  5.8752766],\n",
      "       [-6.199533 , -5.5634637]], dtype=float32), array([[ 9.490048 ],\n",
      "       [-8.9703865]], dtype=float32)]\n",
      "8100 0.018959116 [array([[ 6.0982018,  5.8902197],\n",
      "       [-6.2106423, -5.578793 ]], dtype=float32), array([[ 9.525403],\n",
      "       [-9.007052]], dtype=float32)]\n",
      "8200 0.018600369 [array([[ 6.1083903,  5.904842 ],\n",
      "       [-6.221534 , -5.593789 ]], dtype=float32), array([[ 9.560142],\n",
      "       [-9.043049]], dtype=float32)]\n",
      "8300 0.018254595 [array([[ 6.1183786,  5.9191537],\n",
      "       [-6.2322154, -5.608466 ]], dtype=float32), array([[ 9.59429  ],\n",
      "       [-9.0784025]], dtype=float32)]\n",
      "8400 0.017921107 [array([[ 6.128175 ,  5.933168 ],\n",
      "       [-6.2426944, -5.622834 ]], dtype=float32), array([[ 9.627868],\n",
      "       [-9.113129]], dtype=float32)]\n",
      "8500 0.017599303 [array([[ 6.137785,  5.946896],\n",
      "       [-6.252978, -5.636907]], dtype=float32), array([[ 9.660892],\n",
      "       [-9.147255]], dtype=float32)]\n",
      "8600 0.017288534 [array([[ 6.1472163,  5.960348 ],\n",
      "       [-6.263072 , -5.6506953]], dtype=float32), array([[ 9.693375],\n",
      "       [-9.1808  ]], dtype=float32)]\n",
      "8700 0.016988244 [array([[ 6.156477 ,  5.9735336],\n",
      "       [-6.2729836, -5.66421  ]], dtype=float32), array([[ 9.725344],\n",
      "       [-9.213782]], dtype=float32)]\n",
      "8800 0.016697979 [array([[ 6.1655684,  5.986464 ],\n",
      "       [-6.2827196, -5.6774583]], dtype=float32), array([[ 9.756805],\n",
      "       [-9.246222]], dtype=float32)]\n",
      "8900 0.01641722 [array([[ 6.1745005,  5.9991465],\n",
      "       [-6.2922835, -5.690452 ]], dtype=float32), array([[ 9.787781],\n",
      "       [-9.278133]], dtype=float32)]\n",
      "9000 0.016145576 [array([[ 6.183277 ,  6.0115905],\n",
      "       [-6.3016844, -5.7032   ]], dtype=float32), array([[ 9.818282],\n",
      "       [-9.309538]], dtype=float32)]\n",
      "9100 0.015882462 [array([[ 6.1919017,  6.0238023],\n",
      "       [-6.310923 , -5.7157097]], dtype=float32), array([[ 9.848322 ],\n",
      "       [-9.3404455]], dtype=float32)]\n",
      "9200 0.015627678 [array([[ 6.200381,  6.035793],\n",
      "       [-6.320008, -5.72799 ]], dtype=float32), array([[ 9.877915],\n",
      "       [-9.370873]], dtype=float32)]\n",
      "9300 0.0153807 [array([[ 6.2087193,  6.047568 ],\n",
      "       [-6.328943 , -5.740049 ]], dtype=float32), array([[ 9.907079],\n",
      "       [-9.400836]], dtype=float32)]\n",
      "9400 0.015141281 [array([[ 6.2169204,  6.0591345],\n",
      "       [-6.337732 , -5.751891 ]], dtype=float32), array([[ 9.935818],\n",
      "       [-9.430349]], dtype=float32)]\n",
      "9500 0.014908974 [array([[ 6.2249875,  6.0704985],\n",
      "       [-6.3463798, -5.763526 ]], dtype=float32), array([[ 9.964148],\n",
      "       [-9.459426]], dtype=float32)]\n",
      "9600 0.014683579 [array([[ 6.232927 ,  6.0816674],\n",
      "       [-6.3548903, -5.7749605]], dtype=float32), array([[ 9.99208 ],\n",
      "       [-9.488075]], dtype=float32)]\n",
      "9700 0.014464698 [array([[ 6.2407427,  6.0926485],\n",
      "       [-6.3632693, -5.7861996]], dtype=float32), array([[10.019625],\n",
      "       [-9.516312]], dtype=float32)]\n",
      "9800 0.014252113 [array([[ 6.248434 ,  6.1034465],\n",
      "       [-6.371518 , -5.7972493]], dtype=float32), array([[10.046793],\n",
      "       [-9.544148]], dtype=float32)]\n",
      "9900 0.014045564 [array([[ 6.2560105,  6.114064 ],\n",
      "       [-6.37964  , -5.808116 ]], dtype=float32), array([[10.073595],\n",
      "       [-9.571595]], dtype=float32)]\n",
      "10000 0.013844791 [array([[ 6.263471 ,  6.1245112],\n",
      "       [-6.3876433, -5.818806 ]], dtype=float32), array([[10.100041],\n",
      "       [-9.598662]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[0.01338218]\n",
      " [0.98166394]\n",
      " [0.98809403]\n",
      " [0.01135799]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Lab 9 XOR\n",
    "# This example does not work\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "\n",
    "with tf.name_scope(\"layer3\") as scope:\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "y_hist = tf.summary.histogram(\"y\", Y)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #tensorboard --logdir=./logs/xor_logs\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_logs\", sess.graph)\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "            writer.add_summary(summary, step)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7156377 [array([[ 0.7926959 ,  0.6886104 ],\n",
      "       [-1.2072834 , -0.29517072]], dtype=float32), array([[1.7177    ],\n",
      "       [0.35572484]], dtype=float32)]\n",
      "100 0.6907327 [array([[ 0.32268244, -0.23303036],\n",
      "       [-0.7743417 ,  0.8052943 ]], dtype=float32), array([[1.4608113 ],\n",
      "       [0.78415203]], dtype=float32)]\n",
      "200 0.49503163 [array([[ 1.6721692, -2.3216543],\n",
      "       [-2.2168636,  2.6561468]], dtype=float32), array([[2.8243914],\n",
      "       [2.6025808]], dtype=float32)]\n",
      "300 0.22374642 [array([[ 3.1877632, -3.7442877],\n",
      "       [-3.6972432,  4.1295667]], dtype=float32), array([[4.7004085],\n",
      "       [4.3188057]], dtype=float32)]\n",
      "400 0.12229483 [array([[ 3.9886725, -4.520833 ],\n",
      "       [-4.4841404,  4.903435 ]], dtype=float32), array([[5.8487263],\n",
      "       [5.4189944]], dtype=float32)]\n",
      "500 0.078843184 [array([[ 4.4861465, -5.0151863],\n",
      "       [-4.973251 ,  5.39077  ]], dtype=float32), array([[6.6447487],\n",
      "       [6.2020254]], dtype=float32)]\n",
      "600 0.055981167 [array([[ 4.839386 , -5.370661 ],\n",
      "       [-5.3210588,  5.7398577]], dtype=float32), array([[7.2586293],\n",
      "       [6.8132977]], dtype=float32)]\n",
      "700 0.04224272 [array([[ 5.111045 , -5.645957 ],\n",
      "       [-5.5889034,  6.009811 ]], dtype=float32), array([[7.7626452],\n",
      "       [7.3183374]], dtype=float32)]\n",
      "800 0.033227302 [array([[ 5.3308954, -5.8696966],\n",
      "       [-5.8059134,  6.2290907]], dtype=float32), array([[8.193123],\n",
      "       [7.751217]], dtype=float32)]\n",
      "900 0.026933454 [array([[ 5.515177 , -6.057749 ],\n",
      "       [-5.9879947,  6.413374 ]], dtype=float32), array([[8.57083 ],\n",
      "       [8.131825]], dtype=float32)]\n",
      "1000 0.022333965 [array([[ 5.67365  , -6.219753 ],\n",
      "       [-6.1447105,  6.572153 ]], dtype=float32), array([[8.90876 ],\n",
      "       [8.472787]], dtype=float32)]\n",
      "1100 0.01885244 [array([[ 5.812608 , -6.3619866],\n",
      "       [-6.282229 ,  6.711584 ]], dtype=float32), array([[9.215611],\n",
      "       [8.78262 ]], dtype=float32)]\n",
      "1200 0.016142853 [array([[ 5.9363365, -6.4887395],\n",
      "       [-6.4047527,  6.8358717]], dtype=float32), array([[9.497477 ],\n",
      "       [9.0673685]], dtype=float32)]\n",
      "1300 0.013985719 [array([[ 6.0478745, -6.6030784],\n",
      "       [-6.5152693,  6.9480157]], dtype=float32), array([[9.758837],\n",
      "       [9.331477]], dtype=float32)]\n",
      "1400 0.0122359805 [array([[ 6.1494503, -6.7072563],\n",
      "       [-6.615971 ,  7.0502205]], dtype=float32), array([[10.003056],\n",
      "       [ 9.578303]], dtype=float32)]\n",
      "1500 0.010794317 [array([[ 6.242753 , -6.8029747],\n",
      "       [-6.7085137,  7.1441584]], dtype=float32), array([[10.232743],\n",
      "       [ 9.810454]], dtype=float32)]\n",
      "1600 0.009590316 [array([[ 6.32908  , -6.8915577],\n",
      "       [-6.7941732,  7.2311172]], dtype=float32), array([[10.449962],\n",
      "       [10.03    ]], dtype=float32)]\n",
      "1700 0.008573185 [array([[ 6.4094553, -6.9740477],\n",
      "       [-6.8739595,  7.312116 ]], dtype=float32), array([[10.656366],\n",
      "       [10.238612]], dtype=float32)]\n",
      "1800 0.0077051977 [array([[ 6.484699 , -7.051277 ],\n",
      "       [-6.9486804,  7.387974 ]], dtype=float32), array([[10.853316],\n",
      "       [10.437652]], dtype=float32)]\n",
      "1900 0.006957829 [array([[ 6.5554795, -7.12393  ],\n",
      "       [-7.0189905,  7.459351 ]], dtype=float32), array([[11.041933],\n",
      "       [10.628246]], dtype=float32)]\n",
      "2000 0.006309393 [array([[ 6.6223445, -7.1925664],\n",
      "       [-7.0854316,  7.5267982]], dtype=float32), array([[11.223158],\n",
      "       [10.811347]], dtype=float32)]\n",
      "2100 0.005742714 [array([[ 6.685749 , -7.2576523],\n",
      "       [-7.148453 ,  7.59077  ]], dtype=float32), array([[11.397784],\n",
      "       [10.987764]], dtype=float32)]\n",
      "2200 0.005244485 [array([[ 6.7460775, -7.319577 ],\n",
      "       [-7.208433 ,  7.6516523]], dtype=float32), array([[11.566492],\n",
      "       [11.158178]], dtype=float32)]\n",
      "2300 0.0048038983 [array([[ 6.8036537, -7.3786774],\n",
      "       [-7.2656927,  7.7097683]], dtype=float32), array([[11.729868],\n",
      "       [11.323187]], dtype=float32)]\n",
      "2400 0.004412344 [array([[ 6.8587594, -7.435237 ],\n",
      "       [-7.320504 ,  7.765398 ]], dtype=float32), array([[11.888419],\n",
      "       [11.483295]], dtype=float32)]\n",
      "2500 0.004062689 [array([[ 6.91163  , -7.489502 ],\n",
      "       [-7.3731093,  7.818782 ]], dtype=float32), array([[12.042592],\n",
      "       [11.638964]], dtype=float32)]\n",
      "2600 0.0037491736 [array([[ 6.962477, -7.541683],\n",
      "       [-7.423709,  7.870127]], dtype=float32), array([[12.19277 ],\n",
      "       [11.790581]], dtype=float32)]\n",
      "2700 0.0034669796 [array([[ 7.0114794, -7.5919704],\n",
      "       [-7.4724846,  7.919617 ]], dtype=float32), array([[12.339302 ],\n",
      "       [11.9384985]], dtype=float32)]\n",
      "2800 0.003212058 [array([[ 7.0587955, -7.6405253],\n",
      "       [-7.5195923,  7.9674115]], dtype=float32), array([[12.482494],\n",
      "       [12.083018]], dtype=float32)]\n",
      "2900 0.0029809962 [array([[ 7.104568 , -7.687491 ],\n",
      "       [-7.5651712,  8.013649 ]], dtype=float32), array([[12.622612],\n",
      "       [12.224427]], dtype=float32)]\n",
      "3000 0.0027709822 [array([[ 7.1489196, -7.7329946],\n",
      "       [-7.609344 ,  8.0584545]], dtype=float32), array([[12.759907],\n",
      "       [12.362965]], dtype=float32)]\n",
      "3100 0.002579568 [array([[ 7.1919622, -7.777151 ],\n",
      "       [-7.652218 ,  8.101942 ]], dtype=float32), array([[12.894589],\n",
      "       [12.498854]], dtype=float32)]\n",
      "3200 0.0024046064 [array([[ 7.233792 , -7.8200593],\n",
      "       [-7.693892 ,  8.144206 ]], dtype=float32), array([[13.026862 ],\n",
      "       [12.6322975]], dtype=float32)]\n",
      "3300 0.0022443123 [array([[ 7.274499 , -7.8618126],\n",
      "       [-7.7344537,  8.185339 ]], dtype=float32), array([[13.156905],\n",
      "       [12.763471]], dtype=float32)]\n",
      "3400 0.0020971396 [array([[ 7.314162, -7.902492],\n",
      "       [-7.773981,  8.225419]], dtype=float32), array([[13.284877],\n",
      "       [12.892542]], dtype=float32)]\n",
      "3500 0.001961769 [array([[ 7.352852 , -7.9421716],\n",
      "       [-7.812545 ,  8.264521 ]], dtype=float32), array([[13.410925],\n",
      "       [13.019661]], dtype=float32)]\n",
      "3600 0.0018369715 [array([[ 7.3906364, -7.980915 ],\n",
      "       [-7.8502088,  8.302705 ]], dtype=float32), array([[13.535187],\n",
      "       [13.144961]], dtype=float32)]\n",
      "3700 0.0017217281 [array([[ 7.4275703, -8.018786 ],\n",
      "       [-7.8870325,  8.340034 ]], dtype=float32), array([[13.657784],\n",
      "       [13.26857 ]], dtype=float32)]\n",
      "3800 0.0016151398 [array([[ 7.463711 , -8.055838 ],\n",
      "       [-7.9230676,  8.376559 ]], dtype=float32), array([[13.778829],\n",
      "       [13.390599]], dtype=float32)]\n",
      "3900 0.0015163682 [array([[ 7.4991055, -8.09212  ],\n",
      "       [-7.958363 ,  8.412334 ]], dtype=float32), array([[13.898424],\n",
      "       [13.511158]], dtype=float32)]\n",
      "4000 0.0014247242 [array([[ 7.5337973, -8.127679 ],\n",
      "       [-7.9929643,  8.447398 ]], dtype=float32), array([[14.016665],\n",
      "       [13.630341]], dtype=float32)]\n",
      "4100 0.0013396095 [array([[ 7.567828, -8.162559],\n",
      "       [-8.026908,  8.481797]], dtype=float32), array([[14.133643],\n",
      "       [13.748235]], dtype=float32)]\n",
      "4200 0.0012603657 [array([[ 7.6012373, -8.196796 ],\n",
      "       [-8.060234 ,  8.515567 ]], dtype=float32), array([[14.249437],\n",
      "       [13.864925]], dtype=float32)]\n",
      "4300 0.0011866036 [array([[ 7.634057, -8.230428],\n",
      "       [-8.092978,  8.548741]], dtype=float32), array([[14.364121],\n",
      "       [13.980484]], dtype=float32)]\n",
      "4400 0.0011178144 [array([[ 7.666319, -8.263484],\n",
      "       [-8.125167,  8.581354]], dtype=float32), array([[14.477767],\n",
      "       [14.094987]], dtype=float32)]\n",
      "4500 0.0010535648 [array([[ 7.698053, -8.295999],\n",
      "       [-8.156836,  8.613435]], dtype=float32), array([[14.590436],\n",
      "       [14.208499]], dtype=float32)]\n",
      "4600 0.0009935705 [array([[ 7.729288, -8.327996],\n",
      "       [-8.188007,  8.645012]], dtype=float32), array([[14.70219 ],\n",
      "       [14.321079]], dtype=float32)]\n",
      "4700 0.00093739806 [array([[ 7.760048, -8.359506],\n",
      "       [-8.218708,  8.676106]], dtype=float32), array([[14.813087],\n",
      "       [14.432786]], dtype=float32)]\n",
      "4800 0.00088485295 [array([[ 7.790355, -8.390548],\n",
      "       [-8.248958,  8.706743]], dtype=float32), array([[14.923176],\n",
      "       [14.543669]], dtype=float32)]\n",
      "4900 0.00083560665 [array([[ 7.8202324, -8.421149 ],\n",
      "       [-8.278784 ,  8.736949 ]], dtype=float32), array([[15.032508],\n",
      "       [14.653779]], dtype=float32)]\n",
      "5000 0.0007894051 [array([[ 7.849699 , -8.4513235],\n",
      "       [-8.308202 ,  8.766735 ]], dtype=float32), array([[15.141127],\n",
      "       [14.763162]], dtype=float32)]\n",
      "5100 0.000746024 [array([[ 7.8787746, -8.481094 ],\n",
      "       [-8.337231 ,  8.796127 ]], dtype=float32), array([[15.249074],\n",
      "       [14.871863]], dtype=float32)]\n",
      "5200 0.000705329 [array([[ 7.907476, -8.510482],\n",
      "       [-8.365889,  8.825144]], dtype=float32), array([[15.356389],\n",
      "       [14.979918]], dtype=float32)]\n",
      "5300 0.00066705124 [array([[ 7.935819, -8.539501],\n",
      "       [-8.39419 ,  8.853798]], dtype=float32), array([[15.463109],\n",
      "       [15.087366]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400 0.00063107116 [array([[ 7.9638205, -8.568164 ],\n",
      "       [-8.422157 ,  8.882103 ]], dtype=float32), array([[15.569275],\n",
      "       [15.194242]], dtype=float32)]\n",
      "5500 0.00059719477 [array([[ 7.991493, -8.596491],\n",
      "       [-8.449792,  8.910081]], dtype=float32), array([[15.674908],\n",
      "       [15.300581]], dtype=float32)]\n",
      "5600 0.00056534726 [array([[ 8.018848, -8.62449 ],\n",
      "       [-8.477118,  8.937737]], dtype=float32), array([[15.780047],\n",
      "       [15.406411]], dtype=float32)]\n",
      "5700 0.0005352899 [array([[ 8.045903, -8.65218 ],\n",
      "       [-8.504144,  8.965088]], dtype=float32), array([[15.884717],\n",
      "       [15.511765]], dtype=float32)]\n",
      "5800 0.00050699257 [array([[ 8.07267  , -8.67957  ],\n",
      "       [-8.530881 ,  8.9921465]], dtype=float32), array([[15.98895 ],\n",
      "       [15.616667]], dtype=float32)]\n",
      "5900 0.00048027642 [array([[ 8.099155, -8.706672],\n",
      "       [-8.557341,  9.018921]], dtype=float32), array([[16.092764],\n",
      "       [15.721142]], dtype=float32)]\n",
      "6000 0.00045509645 [array([[ 8.125374, -8.733494],\n",
      "       [-8.583534,  9.045429]], dtype=float32), array([[16.19618 ],\n",
      "       [15.825219]], dtype=float32)]\n",
      "6100 0.00043131848 [array([[ 8.151329, -8.760049],\n",
      "       [-8.60947 ,  9.071665]], dtype=float32), array([[16.299238],\n",
      "       [15.928915]], dtype=float32)]\n",
      "6200 0.00040891254 [array([[ 8.177038, -8.786348],\n",
      "       [-8.635155,  9.097654]], dtype=float32), array([[16.401945],\n",
      "       [16.03224 ]], dtype=float32)]\n",
      "6300 0.00038768476 [array([[ 8.202503, -8.812394],\n",
      "       [-8.660605,  9.123399]], dtype=float32), array([[16.504309],\n",
      "       [16.135246]], dtype=float32)]\n",
      "6400 0.0003676649 [array([[ 8.227735, -8.838202],\n",
      "       [-8.685819,  9.148904]], dtype=float32), array([[16.606369],\n",
      "       [16.237938]], dtype=float32)]\n",
      "6500 0.00034874846 [array([[ 8.252738, -8.863772],\n",
      "       [-8.710809,  9.174183]], dtype=float32), array([[16.708132],\n",
      "       [16.340311]], dtype=float32)]\n",
      "6600 0.00033083116 [array([[ 8.27753  , -8.889124 ],\n",
      "       [-8.735586 ,  9.1992445]], dtype=float32), array([[16.809645],\n",
      "       [16.442425]], dtype=float32)]\n",
      "6700 0.00031388304 [array([[ 8.30211 , -8.914255],\n",
      "       [-8.760155,  9.224084]], dtype=float32), array([[16.910868],\n",
      "       [16.544245]], dtype=float32)]\n",
      "6800 0.00029785934 [array([[ 8.326485, -8.939171],\n",
      "       [-8.784514,  9.248717]], dtype=float32), array([[17.011858],\n",
      "       [16.645817]], dtype=float32)]\n",
      "6900 0.0002826855 [array([[ 8.3506565, -8.963882 ],\n",
      "       [-8.808678 ,  9.2731495]], dtype=float32), array([[17.112621],\n",
      "       [16.747158]], dtype=float32)]\n",
      "7000 0.0002683317 [array([[ 8.374637, -8.988395],\n",
      "       [-8.83265 ,  9.297393]], dtype=float32), array([[17.213171],\n",
      "       [16.848274]], dtype=float32)]\n",
      "7100 0.00025473826 [array([[ 8.398429, -9.012715],\n",
      "       [-8.856439,  9.321448]], dtype=float32), array([[17.313494],\n",
      "       [16.949194]], dtype=float32)]\n",
      "7200 0.00024184554 [array([[ 8.422035, -9.036848],\n",
      "       [-8.880043,  9.345316]], dtype=float32), array([[17.41363 ],\n",
      "       [17.049894]], dtype=float32)]\n",
      "7300 0.0002296386 [array([[ 8.445466, -9.060798],\n",
      "       [-8.90347 ,  9.369008]], dtype=float32), array([[17.513575],\n",
      "       [17.15041 ]], dtype=float32)]\n",
      "7400 0.00021810248 [array([[ 8.468724, -9.084571],\n",
      "       [-8.926726,  9.392517]], dtype=float32), array([[17.613344],\n",
      "       [17.250736]], dtype=float32)]\n",
      "7500 0.00020710306 [array([[ 8.491817 , -9.1081705],\n",
      "       [-8.949819 ,  9.415861 ]], dtype=float32), array([[17.71295 ],\n",
      "       [17.350893]], dtype=float32)]\n",
      "7600 0.00019672974 [array([[ 8.514756, -9.131594],\n",
      "       [-8.97275 ,  9.439036]], dtype=float32), array([[17.812443],\n",
      "       [17.450882]], dtype=float32)]\n",
      "7700 0.00018689307 [array([[ 8.537529, -9.154857],\n",
      "       [-8.995517,  9.462054]], dtype=float32), array([[17.911798],\n",
      "       [17.55073 ]], dtype=float32)]\n",
      "7800 0.00017753342 [array([[ 8.560148, -9.177964],\n",
      "       [-9.018139,  9.484902]], dtype=float32), array([[18.01098],\n",
      "       [17.65045]], dtype=float32)]\n",
      "7900 0.00016868059 [array([[ 8.58261 , -9.200906],\n",
      "       [-9.040603,  9.507606]], dtype=float32), array([[18.110043],\n",
      "       [17.750013]], dtype=float32)]\n",
      "8000 0.00016026004 [array([[ 8.604927, -9.223698],\n",
      "       [-9.062923,  9.530157]], dtype=float32), array([[18.209024],\n",
      "       [17.849438]], dtype=float32)]\n",
      "8100 0.00015233137 [array([[ 8.627097, -9.246344],\n",
      "       [-9.085099,  9.552573]], dtype=float32), array([[18.307825],\n",
      "       [17.94881 ]], dtype=float32)]\n",
      "8200 0.00014473063 [array([[ 8.649122, -9.26884 ],\n",
      "       [-9.107138,  9.57484 ]], dtype=float32), array([[18.40655 ],\n",
      "       [18.048016]], dtype=float32)]\n",
      "8300 0.00013754726 [array([[ 8.671009, -9.291199],\n",
      "       [-9.129032,  9.596966]], dtype=float32), array([[18.50516 ],\n",
      "       [18.147177]], dtype=float32)]\n",
      "8400 0.0001307365 [array([[ 8.692767, -9.313413],\n",
      "       [-9.150804,  9.618952]], dtype=float32), array([[18.60369 ],\n",
      "       [18.246168]], dtype=float32)]\n",
      "8500 0.00012426857 [array([[ 8.714383, -9.335491],\n",
      "       [-9.172426,  9.640811]], dtype=float32), array([[18.702108],\n",
      "       [18.34514 ]], dtype=float32)]\n",
      "8600 0.00011811364 [array([[ 8.735879, -9.357439],\n",
      "       [-9.193929,  9.662524]], dtype=float32), array([[18.800495],\n",
      "       [18.443941]], dtype=float32)]\n",
      "8700 0.00011228661 [array([[ 8.757246, -9.379246],\n",
      "       [-9.21531 ,  9.684117]], dtype=float32), array([[18.898724],\n",
      "       [18.542742]], dtype=float32)]\n",
      "8800 0.00010675766 [array([[ 8.778482, -9.400931],\n",
      "       [-9.236554,  9.705579]], dtype=float32), array([[18.996952],\n",
      "       [18.641373]], dtype=float32)]\n",
      "8900 0.000101482095 [array([[ 8.799601, -9.422488],\n",
      "       [-9.257682,  9.726914]], dtype=float32), array([[19.09508 ],\n",
      "       [18.739983]], dtype=float32)]\n",
      "9000 9.648972e-05 [array([[ 8.820603, -9.443914],\n",
      "       [-9.278695,  9.748132]], dtype=float32), array([[19.193117],\n",
      "       [18.838554]], dtype=float32)]\n",
      "9100 9.17507e-05 [array([[ 8.841476, -9.465224],\n",
      "       [-9.29959 ,  9.769236]], dtype=float32), array([[19.291155],\n",
      "       [18.936974]], dtype=float32)]\n",
      "9200 8.723523e-05 [array([[ 8.862236, -9.486419],\n",
      "       [-9.320361,  9.790216]], dtype=float32), array([[19.389118],\n",
      "       [19.035393]], dtype=float32)]\n",
      "9300 8.292843e-05 [array([[ 8.882884, -9.507487],\n",
      "       [-9.341022,  9.811074]], dtype=float32), array([[19.486965],\n",
      "       [19.133812]], dtype=float32)]\n",
      "9400 7.886008e-05 [array([[ 8.903426, -9.528439],\n",
      "       [-9.361573,  9.831823]], dtype=float32), array([[19.584812],\n",
      "       [19.232052]], dtype=float32)]\n",
      "9500 7.498548e-05 [array([[ 8.923856, -9.549279],\n",
      "       [-9.382017,  9.852462]], dtype=float32), array([[19.68266],\n",
      "       [19.33028]], dtype=float32)]\n",
      "9600 7.133442e-05 [array([[ 8.944176, -9.57001 ],\n",
      "       [-9.402355,  9.87299 ]], dtype=float32), array([[19.780436],\n",
      "       [19.428509]], dtype=float32)]\n",
      "9700 6.7817506e-05 [array([[ 8.964386 , -9.590632 ],\n",
      "       [-9.422586 ,  9.8934145]], dtype=float32), array([[19.878092],\n",
      "       [19.52673 ]], dtype=float32)]\n",
      "9800 6.450922e-05 [array([[ 8.98449 , -9.611148],\n",
      "       [-9.442713,  9.913729]], dtype=float32), array([[19.975748],\n",
      "       [19.624792]], dtype=float32)]\n",
      "9900 6.136488e-05 [array([[ 9.004492, -9.631549],\n",
      "       [-9.462732,  9.933935]], dtype=float32), array([[20.073404],\n",
      "       [19.72283 ]], dtype=float32)]\n",
      "10000 5.8339763e-05 [array([[ 9.024394, -9.651845],\n",
      "       [-9.482652,  9.95404 ]], dtype=float32), array([[20.17106 ],\n",
      "       [19.820868]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[6.1310318e-05]\n",
      " [9.9993694e-01]\n",
      " [9.9995077e-01]\n",
      " [5.9751477e-05]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Lab 9 XOR\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_logs_r0_01\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 9 XOR + graph supplement \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_logs_r0_01\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 9 XOR-back_prop  : lab-09-2-xor-nn-back_prop.py \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.1\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "def sigmoidGradient(z):\n",
    "  return tf.multiply(tf.sigmoid(z), (1 - tf.sigmoid(z)))\n",
    "\n",
    "diff = hypothesis - Y\n",
    "\n",
    "d_l2 = tf.multiply(diff, sigmoidGradient(tf.matmul(layer1, W2) + b2))\n",
    "d_b2 = d_l2\n",
    "d_W2 = tf.matmul(tf.transpose(layer1), d_l2)\n",
    "\n",
    "d_l1 = tf.multiply(tf.matmul(d_l2, tf.transpose(W2)), sigmoidGradient(tf.matmul(X, W1) + b1))\n",
    "d_b1 = d_l1\n",
    "d_W1 = tf.matmul(tf.transpose(X), d_l1)\n",
    "\n",
    "step = [\n",
    "  tf.assign(W2, W2 - learning_rate * d_W2),\n",
    "  tf.assign(b2, b2 - learning_rate * tf.reduce_mean(d_b2, axis=[0])),\n",
    "  tf.assign(W1, W1 - learning_rate * d_W1),\n",
    "  tf.assign(b1, b1 - learning_rate * tf.reduce_mean(d_b1, axis=[0]))\n",
    "]\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis > 0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(10001):\n",
    "        sess.run([step, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if i % 1000 == 0:\n",
    "            print(i, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n",
    "\n",
    "\n",
    "'''\n",
    "Hypothesis:  [[ 0.07884014]\n",
    " [ 0.88706875]\n",
    " [ 0.94088489]\n",
    " [ 0.04933683]]\n",
    "Correct:  [[ 0.]\n",
    " [ 1.]\n",
    " [ 1.]\n",
    " [ 0.]]\n",
    "Accuracy:  1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 9 XOR :  lab-09-4-xor_tensorboard.py  \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_logs_r0_01\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n",
    "\n",
    "\n",
    "'''\n",
    "Hypothesis:  [[  6.13103184e-05]\n",
    " [  9.99936938e-01]\n",
    " [  9.99950767e-01]\n",
    " [  5.97514772e-05]]\n",
    "Correct:  [[ 0.]\n",
    " [ 1.]\n",
    " [ 1.]\n",
    " [ 0.]]\n",
    "Accuracy:  1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
