{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lab-11-0-cnn_basics.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x238ff61e6d8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]], \n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e5db7365c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plt.imshow\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]], \n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "# plt.imshow(image.reshape(3,3), cmap='Greys')\n",
    "# plt.imshow(image.shape(1,3,3,1), cmap='Greys')\n",
    "plt.imshow(image.reshape(1,9), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## simple convolution layer with padding valid\n",
    "\n",
    "# print(\"imag:\\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='VALID')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight.shape (2, 2, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'TensorShape' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-3ac155dc71f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weight.shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# plt.imshow(weight.reshape(1, 4), cmap='Greys')\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# plt.imshow(weight)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcamp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greys'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'TensorShape' object is not callable"
     ]
    }
   ],
   "source": [
    "##  fileter shape\n",
    " \n",
    "weight = tf.constant([[[1.],[1.]],\n",
    "                      [[1.],[1.]]])\n",
    "print(\"weight.shape\", weight.shape)   # plt.imshow(weight.reshape(1, 4), cmap='Greys') \n",
    "# plt.imshow(weight) \n",
    "plt.imshow(weight.shape(2, 2, 1), camp='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot([1,2,3,4,5,6,7,8,9,8,7,6,5,4,3,2,1,0])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"hello\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAAC7CAYAAADPLLrPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACWpJREFUeJzt3X2IZXUdx/H3J1enRavdWmuX9WGNFskeIB1HRZAlWdBFXCGD9Y98QBkQpQcK0gKDILH+KJINY0uxiVDDYttkY1G0NErZUdaHdVmdJHBxwRxzt0Vbmfr2xz3V9Xpnv7N7fvO7MzufF1zmnHt+M9/fZfhw7jnn3u9RRGBm03vPoCdgNtc5JGYJh8Qs4ZCYJRwSs4RDYpZoFRJJH5T0oKQXm59Lpxn3L0k7mseWNjXNalOb6ySSvge8HhG3SboJWBoRX+8z7kBEnNBinmYD0zYku4E1EbFX0grg9xFxep9xDonNW22PST4SEXsBmp8fnmbceyWNS3pc0mUta5pVtSgbIOkhYHmfTd88jDqnRMQrkj4KPCzp2Yj4S59ao8Bos3zW0NDQYZSYu44//vhBT6GYycnJQU+hpNci4sRsUJW3Wz2/czfwQETcf6hxixcvjlWrVh3x3OaSkZGRQU+hmLGxsUFPoaQnI2I4G9T27dYW4Kpm+SrgN70DJC2VNNQsLwPOB55vWdesmrYhuQ1YK+lFYG2zjqRhST9txnwcGJf0NPAIcFtEOCQ2b6THJIcSEZPAhX2eHweua5b/BHyqTR2zQfIVd7OEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCzhkJglHBKzRJGQSLpI0m5JE02Tut7tQ5Lua7Y/IWlVibpmNbQOiaRjgB8BFwNnAFdIOqNn2LXA3yPiY8APgO+2rWtWS4k9yQgwEREvRcTbwL3A+p4x64GfNcv3AxdKUoHaZrOuREhWAi93re9pnus7JiKmgH3Ah3r/kKTRptPj+NTUVIGpmbVXIiT99gi9He9mMoaI2BQRwxExvGhRq0YuZsWUCMke4OSu9ZOAV6YbI2kR8AHg9QK1zWZdiZBsB1ZLOk3SccAGOp0du3V3erwceDh8b2ybJ1q/p4mIKUk3AtuAY4C7ImKnpG8D4xGxBbgT+LmkCTp7kA1t65rVUuSNf0RsBbb2PHdL1/I/gc+XqGVWm6+4myUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCxRqznd1ZL+JmlH87iuRF2zGlp/M7GrOd1aOg0ftkvaEhHP9wy9LyJubFvPrLZazenM5q0S33Hv15zunD7jPifpAuAF4CsR8XLvAEmjwCjA8uXLGRsbKzC9wTv77LMHPYVi9u/fP+gpFLN58+YZjavVnO63wKqI+DTwEP9vefrOX+pqTrdkyZICUzNrr0pzuoiYjIiDzepPgLMK1DWrokpzOkkrulYvBXYVqGtWRa3mdF+UdCkwRac53dVt65rVUqs53c3AzSVqmdXmK+5mCYfELOGQmCUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExS5RqTneXpFclPTfNdkm6vWle94ykM0vUNauh1J7kbuCiQ2y/GFjdPEaBOwrVNZt1RUISEY/S+e76dNYDY9HxOLCkpzmE2ZxV65ikXwO7lZVqm7VSKyQzaWCHpFFJ45LG33jjjQrTMsvVCknawA7cwdHmploh2QJc2ZzlOhfYFxF7K9U2a6VI3y1J9wBrgGWS9gDfAo4FiIgf0+nJtQ6YAN4ErilR16yGUs3prki2B3BDiVpmtfmKu1nCITFLOCRmCYfELOGQmCUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZolYHxzWS9kna0TxuKVHXrIYiX9+l08FxIzB2iDGPRcQlheqZVVOrg6PZvFVqTzIT50l6mk6/ra9FxM7eAZJG6fQKZvHixdx6660Vpzd7Vq48eppVbt68edBTqK5WSJ4CTo2IA5LWAZvpNM9+h4jYBGwCWLp06bs6PJoNQpWzWxGxPyIONMtbgWMlLatR26ytKiGRtFySmuWRpu5kjdpmbdXq4Hg5cL2kKeAtYEPTsM5szqvVwXEjnVPEZvOOr7ibJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCzhkJglHBKzhENilnBIzBIOiVnCITFLOCRmCYfELNE6JJJOlvSIpF2Sdkr6Up8xknS7pAlJz0g6s21ds1pKfDNxCvhqRDwl6X3Ak5IejIjnu8ZcTKc7ymrgHOCO5qfZnNd6TxIReyPiqWb5H8AuoLfR1HpgLDoeB5ZIWtG2tlkNRY9JJK0CPgM80bNpJfBy1/oe3h0kJI1KGpc0fvDgwZJTMztixUIi6QTgV8CXI2J/7+Y+v/KubikRsSkihiNieGhoqNTUzFop1VX+WDoB+UVE/LrPkD3AyV3rJ9Fpd2o255U4uyXgTmBXRHx/mmFbgCubs1znAvsiYm/b2mY1lDi7dT7wBeBZSTua574BnAL/a063FVgHTABvAtcUqGtWReuQRMQf6X/M0T0mgBva1jIbBF9xN0s4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCzhkJglHBKzhENilnBIzBIOiVmiVnO6NZL2SdrRPG5pW9esllrN6QAei4hLCtQzq6pWczqzeatWczqA8yQ9Lel3kj5Rsq7ZbFKnR0OBP9RpTvcH4Du9vbckvR/4d0QckLQO+GFErO7zN0aB0Wb1dGB3kckd2jLgtQp1ajhaXkut13FqRJyYDSoSkqY53QPAtkP03uoe/1dgOCIG/g+VNB4Rw4OeRwlHy2uZa6+jSnM6ScubcUgaaepOtq1tVkOt5nSXA9dLmgLeAjZEqfd5ZrOsVnO6jcDGtrVmyaZBT6Cgo+W1zKnXUezA3exo5Y+lmCUWbEgkXSRpd3Mfx5sGPZ8jJekuSa9Kem7Qc2lrJh9xGoQF+XZL0jHAC8BaOvdO2Q5c0eejNHOepAuAA3Rut/fJQc+njeYWgSu6P+IEXDbo/8tC3ZOMABMR8VJEvA3cS+e+jvNORDwKvD7oeZQwVz/itFBDMqN7ONrgJB9xqmqhhmRG93C0wUjuv1ndQg2J7+E4R83g/pvVLdSQbAdWSzpN0nHABjr3dbQBmuH9N6tbkCGJiCngRmAbnYPDX0bEzsHO6shIugf4M3C6pD2Srh30nFr470ecPtv1LdZ1g57UgjwFbHY4FuSexOxwOCRmCYfELOGQmCUcErOEQ2KWcEjMEg6JWeI/TTEFLVhDkXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## simple convolution layer with padding same\n",
    "\n",
    "# print(\"imag:\\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 3)\n",
      "conv2d_img.shape (1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 3 filters (2,2,1,3)\n",
    "\n",
    "# print(\"imag:\\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "weight = tf.constant([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
    "                      [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[4.]]]]\n"
     ]
    }
   ],
   "source": [
    "## Max pooling\n",
    "\n",
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='VALID')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[4.]\n",
      "   [3.]]\n",
      "\n",
      "  [[2.]\n",
      "   [1.]]]]\n"
     ]
    }
   ],
   "source": [
    "## zero padding\n",
    "\n",
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-a43f9f63cc55>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2388664a5c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_3:0\", shape=(1, 14, 14, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img = img.reshape(-1,28,28,1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 5], stddev=0.01))\n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(conv2d)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_2:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABcCAYAAABOZ1+dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACgdJREFUeJzt3U1MFGkaB/D/A6QhTAOCHxPBj6iMroSNiSF68GC8jO7BTODknv04qfFkNno0McaY6Bq9GDMXlMzB4AfJZHROTvSgQhQHV1HX6KhIdKCVRb4WePYArD1U8b7VVFd3v8P/lxiln7LeZ/5TPGmL6ipRVRARkTvyst0AERGlhoObiMgxHNxERI7h4CYicgwHNxGRYzi4iYgcw8FNROQYDm4iIsdwcBMROaYgip0WFhZqPB6PYtc5o7+/H8PDwxJ0exGZKx9R/V1VFwbZcN68eVpZWRl1P1n3+PHjwJnwOPFXXl6uVVVVUfaTdW/fvkUikQg0UwINbhHZBuCfAPIBnFfVY6bt4/E4tm7dGmTXzmppaYGIdCJgJnNIiYg8R4BMKisr0djYmKG2sqeuri7BY8UjpUyqqqrQ3Nycmc6ypKGhIfC21lMlIpIP4CyAvwGoAfB3EamZdXd/AuPj4xgYGACYiZ+nYCb/NzY2BgDLwGNlOmYSQpBz3BsAPFfVF6o6AuAHAN9F21Zu6+3tRV5eHpiJrxFm8sWjR48AYJjHigczCSHI4K4C8Drp6zeTr/2BiOwRkVYRaR0aGkpXfzlpYGAA+fn5yS9ZM8lYc7nDmkkikchCW5n1/v17ABhJesmTyxw9ToyZAHPvWElFkMHtd7Lc8wMUVT2nqnWqWldUVBS+M/cYM8lGQznAmEl5eXk2esoFf8iFxwkAHispCTK43wBYmvT1EgBd0bTjhuLi4qlzl1PmfCY+mAmARYsWAUAs6SXmMoGZhBBkcN8D8I2IrBCRGIAdAK5F21Zuq6iowPj4OJiJrxgz+aKmpgYAiniseDCTEKyXA6rqqIjsBXAdE5fufK+qj0x/Jx6PY/PmzTPW16xZY23Mdk7r8+fPxvqtW7eM9b6+PmsPM8nLy0NxcTH6+/sDZ5IOK1euNNaLi4uN9cLCQmO9ra0t5Z58rAbwGAEyKSoqwtq1a2esf/r0ybpYV1duv1ErKCgAgN8Q8PsnFoth8eLFM+7P9H01pbq62lhfsWKFsX7kyBFj/enTp9YeAgicCTBxrJj+u0Tslz93d3cb6yUlJcZ6Lh1rga7jVtUfAfwYcS9OicViUNXV2e4jB3XM8XO1fj4xEw9mEgI/8k5E5BgObiIix3BwExE5hoObiMgxHNxERI7h4CYicgwHNxGRYyJ5kEJBQQFM9xbYsmWLdR8bN24M1cO0m0B5LF++PNT+U1VRUWG8R7mtXwBYv369sf7w4UNjvb6+3li/ceOGtYezZ89atwmqv7/f+EGpyRs0GdmOE9uHJtrb2431TZs2WXtIp6VLl+LEiRMz1m/evGndx7Vr5g8h2u4lZLuXfpAP0LW0tFi3SUVvby+amppmrJ85c8a6jwMHDoTqYdWqVcZ6WVlZqP2ngu+4iYgcw8FNROQYDm4iIsdwcBMROYaDm4jIMRzcRESO4eAmInKMqHoe9Rba/Pnz1XYtqM2hQ4eM9du3bxvrtut7jx8/nnJPya5fv46enh773dsniUj6g57m6NGjxvrkE8dndOHCBesaAW5Y3xb0Pss1NTXa2NgYZNMZ2a6tHRwcNNYrKyuN9dbW8M/vraurC5xJOo6TnTt3Guvnz5831q9cuWKsX7x40drDpUuXbJsEzgQAamtrtbm5OejmvpYtW2as2x7OsmDBAmO9s7Mz5Z6SNTQ0oKOjI9BM4TtuIiLHcHATETmGg5uIyDEc3EREjuHgJiJyDAc3EZFjOLiJiBwTyf24bY4dO2bd5tSpU8Z6d3e3sb5jx46Uesq2devWWbfZvn27sf7u3Ttj3XYf5vv371t7yKQlS5ZYt3n27JmxbrtHsi3TXLN//37rNrt37zbWbdfi79u3z1i/c+eOtYdMW7hwoXWbvXv3GusHDx401rdt25ZST1HiO24iIsdwcBMROYaDm4jIMRzcRESO4eAmInIMBzcRkWM4uImIHJOV67gPHz5s3WZsbMxYb2pqMtbv3r2bUk/Z1t7enpZtTK5evWqs19fXh9p/uo2Pj1u3ycszv/dYvXq1sW67djcWi1l7GBkZsW6TLqdPnw69za5du4z10tJSY/3169fWHjLtw4cP1m1s/69tx0p1dXVKPUUp0OAWkZcA/gNgDMBoKjdA/7P6+PEjRORXMJPp/spcPJiJFzMJIZV33FtU9ffIOnETM/HHXLyYiRczmSWe4yYickzQwa0AbohIm4js8dtARPaISKuItA4NDaWvw9wWOJNMN5ZlM+aSnEkikchGb9kSKJNsNJZFgb9/5tixYhX0VMkmVe0SkUUAfhaRJ6r6S/IGqnoOwDlg4mHBae4z55SWliKRSKwPmkkmHhacI56o6oy5JGdSU1PDTMDjBAG+f2pra+dKLoEEesetql2Tv78HcBnAhiibcsHU1QzMxOO/AHOZhpl4MZMQrINbRL4SkZKpPwP4FkBH1I3lstHRUahOvAFgJh55AHOZMjg4CDATP8wkhCCnSr4GcHnyHr4FAJpU9adIu8pxQ0ND6Ovrg4i0g5lM9xfm8kVPTw/ATPwwkxCsg1tVXwCw3+U/BbYP1wRx8uRJY/3evXuh15hJPB5HWVkZenp60ppL1GwfSnr16lU6lvlXuq7J7erqCr0P23Ewb948Y314eDjU+pMPg0hbJunw4MEDY721NSM/I82pTACgs7PTWLc9YCKTeDkgEZFjOLiJiBzDwU1E5BgObiIix3BwExE5hoObiMgxHNxERI6RqU8ApnWnIh8AJF8UvABArt++MdUel6vqwqAbz5FMgBRyYSZePpnMds1M4/ePV2SZRDK4PYuItObaxfbTZbpHZpL99WYjGz0yl+yvNxtR9shTJUREjuHgJiJyTKYG97kMrRNGpntkJtlfbzay0SNzyf56sxFZjxk5x01EROnDUyVERI6JdHCLyDYR6RSR5yLyjyjXCkNEXorIryLyIOrn/jGTGdfL+VyYiRcz8Rd5LqoayS8A+QD+DWAlgBiAdgA1Ua0XsteXABZkYB1m4nAuzISZ5EouUb7j3gDguaq+UNURAD8A+C7C9VzATPwxFy9m4sVMJkU5uKsAvE76+s3ka7lIAdwQkTYR2RPhOszEnyu5MBMvZuIv0lyCPHNytsTntVy9hGWTqnaJyCIAP4vIE1X9JYJ1mIk/V3JhJl7MxF+kuUT5jvsNgKVJXy8BEP4hghFQ1a7J398DuIyJf5JFgZn4cyIXZuLFTPxFnUuUg/segG9EZIWIxADsAHAtwvVmRUS+EpGSqT8D+BZAR0TLMRN/OZ8LM/FiJv4ykUtkp0pUdVRE9gK4jomfBn+vqo+iWi+ErwFcFhFgIo8mVf0pioWYiT9HcmEmXszEX+S58JOTRESO4ScniYgcw8FNROQYDm4iIsdwcBMROYaDm4jIMRzcRESO4eAmInIMBzcRkWP+B+tcgqnojsPQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[\n",
    "                        1, 2, 2, 1], padding='SAME')\n",
    "print(pool)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-12-d5cd891f6436>:102: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.343460995\n",
      "Epoch: 0002 cost = 0.102303201\n",
      "Epoch: 0003 cost = 0.075425078\n",
      "Epoch: 0004 cost = 0.063667369\n",
      "Epoch: 0005 cost = 0.049824893\n",
      "Epoch: 0006 cost = 0.047056068\n",
      "Epoch: 0007 cost = 0.042863490\n",
      "Epoch: 0008 cost = 0.038387453\n",
      "Epoch: 0009 cost = 0.035094870\n",
      "Epoch: 0010 cost = 0.034307162\n",
      "Epoch: 0011 cost = 0.030387152\n",
      "Epoch: 0012 cost = 0.029923820\n",
      "Epoch: 0013 cost = 0.026512925\n",
      "Epoch: 0014 cost = 0.026125674\n",
      "Epoch: 0015 cost = 0.026441103\n",
      "Learning Finished!\n",
      "Accuracy: 0.9933\n",
      "Label:  [4]\n",
      "Prediction:  [4]\n"
     ]
    }
   ],
   "source": [
    "## lab-11-2-mnist_deep_cnn.py\n",
    "### Learning started. It takes sometime ( 30 minutes)\n",
    "\n",
    "# Lab 11 MNIST and Deep learning CNN\n",
    "import tensorflow as tf\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "'''\n",
    "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "'''\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "\n",
    "# if you have a OOM error, please refer to lab-11-X-mnist_deep_cnn_low_memory.py\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "# plt.imshow(mnist.test.images[r:r + 1].\n",
    "#           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'iris_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2f9a9cb8d653>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0miris_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'iris_data'"
     ]
    }
   ],
   "source": [
    "## mnist dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "import iris_data\n",
    "print(mnist.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Learning Started!\n",
      "Epoch: 0001 cost = 0.373102779\n",
      "Learning Finished!\n",
      "Accuracy: 0.9809\n"
     ]
    }
   ],
   "source": [
    "## lab-11-3-mnist_cnn_class.py : epoch = 1 takes 3 minutes\n",
    "\n",
    "# Lab 11 MNIST and Deep learning CNN\n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "# eopchs 15 -> 1 \n",
    "training_epochs = 1\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            # img 28x28x1 (black/white)\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "            #    Conv     -> (?, 28, 28, 32)\n",
    "            #    Pool     -> (?, 14, 14, 32)\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "            #    Conv      ->(?, 14, 14, 64)\n",
    "            #    Pool      ->(?, 7, 7, 64)\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "            #    Conv      ->(?, 7, 7, 128)\n",
    "            #    Pool      ->(?, 4, 4, 128)\n",
    "            #    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                                1, 2, 2, 1], padding='SAME')\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "\n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "            '''\n",
    "            Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "            Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L5 Final FC 625 inputs -> 10 outputs\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5) + b5\n",
    "            '''\n",
    "            Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "            '''\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def train(self, x_data, y_data, keep_prop=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "m1 = Model(sess, \"m1\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Learning Started!\n",
      "Epoch: 0001 cost = 0.277537650\n",
      "Learning Finished!\n",
      "Accuracy: 0.9843\n"
     ]
    }
   ],
   "source": [
    "## lab-11-4-mnist_cnn_layers.py\n",
    "### training_epochs = 15 -> 1\n",
    "\n",
    "\n",
    "# Lab 11 MNIST and Deep learning CNN\n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "            # img 28x28x1 (black/white), Input Layer\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # Convolutional Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            # Pooling Layer #1\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"same\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
    "            dense4 = tf.layers.dense(inputs=flat,\n",
    "                                     units=625, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
    "                                         rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits,\n",
    "                             feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                             feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "m1 = Model(sess, \"m1\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Learning Started!\n",
      "Epoch: 0001 cost = [0.28189685 0.28772883]\n",
      "Learning Finished!\n",
      "0 Accuracy: 0.9823\n",
      "1 Accuracy: 0.9835\n",
      "Ensemble accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "## lab-11-5-mnist_cnn_ensemble_layers.py\n",
    "### training_epochs = 20 --> 1\n",
    "\n",
    "\n",
    "# Lab 11 MNIST and Deep learning CNN\n",
    "# https://www.tensorflow.org/tutorials/layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "            # img 28x28x1 (black/white), Input Layer\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # Convolutional Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            # Pooling Layer #1\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #3 and Pooling Layer #3\n",
    "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
    "            dense4 = tf.layers.dense(inputs=flat,\n",
    "                                     units=625, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
    "                                         rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits,\n",
    "                             feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                             feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "\n",
    "models = []\n",
    "num_models = 2\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros([test_size, 10])\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable W4 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3670616c72ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m# W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625], initializer=tf.contrib.layers.xavier_initializer())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0mW4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m128\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m625\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[0mb4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m625\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mL4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1485\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1235\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1237\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mc:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    538\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mc:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    859\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 861\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    862\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable W4 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\users\\beomc\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## lab-11-X-mnist_cnn_low_memory.py\n",
    "### training_epochs = 15  -> 1 \n",
    "### tf.get_variable error \n",
    "\n",
    "# Lab 10 MNIST and Deep learning CNN\n",
    "import tensorflow as tf\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1\n",
    "batch_size = 100\n",
    "\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3 = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "'''\n",
    "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "\n",
    "# W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625], initializer=tf.contrib.layers.xavier_initializer())\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625], initializer=tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32))\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "'''\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning stared. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _, = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "def evaluate(X_sample, y_sample, batch_size=512):\n",
    "    \"\"\"Run a minibatch accuracy op\"\"\"\n",
    "\n",
    "    N = X_sample.shape[0]\n",
    "    correct_sample = 0\n",
    "\n",
    "    for i in range(0, N, batch_size):\n",
    "        X_batch = X_sample[i: i + batch_size]\n",
    "        y_batch = y_sample[i: i + batch_size]\n",
    "        N_batch = X_batch.shape[0]\n",
    "\n",
    "        feed = {\n",
    "            X: X_batch,\n",
    "            Y: y_batch,\n",
    "            keep_prob: 1\n",
    "        }\n",
    "\n",
    "        correct_sample += sess.run(accuracy, feed_dict=feed) * N_batch\n",
    "\n",
    "    return correct_sample / N\n",
    "\n",
    "print(\"\\nAccuracy Evaluates\")\n",
    "print(\"-------------------------------\")\n",
    "print('Train Accuracy:', evaluate(mnist.train.images, mnist.train.labels))\n",
    "print('Test Accuracy:', evaluate(mnist.test.images, mnist.test.labels))\n",
    "\n",
    "\n",
    "# Get one and predict\n",
    "print(\"\\nGet one and predict\")\n",
    "print(\"-------------------------------\")\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), {X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "# plt.imshow(mnist.test.images[r:r + 1].\n",
    "#           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
